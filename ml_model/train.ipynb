{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e39139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from playlist import optimized_pomodoro_playlist  # Import your logic\n",
    "\n",
    "# List all possible patterns, mapping string to integer class\n",
    "PATTERN_LIST = [\n",
    "    \"WSW\",\n",
    "    \"WSWSWL\",\n",
    "    \"WSWSWSWL\",\n",
    "    \"WSWSWSWL+WSWS\",\n",
    "    \"2×WSWSWL\",\n",
    "    \"2×WSWSWSWL\",\n",
    "]\n",
    "PATTERN_TO_IDX = {p: i for i, p in enumerate(PATTERN_LIST)}\n",
    "IDX_TO_PATTERN = {i: p for p, i in PATTERN_TO_IDX.items()}\n",
    "MAX_SESSIONS = 8  # Maximum number of work sessions across all patterns\n",
    "\n",
    "def generate_dataset():\n",
    "    X, y_pattern, y_sessions, y_breaks = [], [], [], []\n",
    "    for mins in range(30, 360 + 1, 5):\n",
    "        result = optimized_pomodoro_playlist(f\"{mins}:00\", code_format=False)\n",
    "        # Input: duration as float\n",
    "        X.append([float(mins)])\n",
    "        # Pattern class (int)\n",
    "        y_pattern.append(PATTERN_TO_IDX[result[\"sequence\"]])\n",
    "        # Work sessions (list, pad to MAX_SESSIONS with 0s)\n",
    "        ws = result[\"work_sessions\"] + [0]*(MAX_SESSIONS-len(result[\"work_sessions\"]))\n",
    "        y_sessions.append(ws)\n",
    "        # Short/Long break\n",
    "        short = result[\"short_break\"]\n",
    "        long_ = result[\"long_break\"] if result[\"long_break\"] is not None else 0\n",
    "        y_breaks.append([short, long_])\n",
    "    return np.array(X), np.array(y_pattern), np.array(y_sessions), np.array(y_breaks)\n",
    "\n",
    "X, y_pattern, y_sessions, y_breaks = generate_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1090290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PomodoroDataset(Dataset):\n",
    "    def __init__(self, X, y_pattern, y_sessions, y_breaks):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y_pattern = torch.tensor(y_pattern, dtype=torch.long)\n",
    "        self.y_sessions = torch.tensor(y_sessions, dtype=torch.float32)\n",
    "        self.y_breaks = torch.tensor(y_breaks, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y_pattern[idx], self.y_sessions[idx], self.y_breaks[idx]\n",
    "\n",
    "dataset = PomodoroDataset(X, y_pattern, y_sessions, y_breaks)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b53fedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PomodoroNet(nn.Module):\n",
    "    def __init__(self, num_patterns, max_sessions):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pattern_head = nn.Linear(64, num_patterns)      # Classification\n",
    "        self.sessions_head = nn.Linear(64, max_sessions)     # Regression\n",
    "        self.breaks_head = nn.Linear(64, 2)                  # Regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.shared(x)\n",
    "        pattern_logits = self.pattern_head(features)\n",
    "        sessions_pred = self.sessions_head(features)\n",
    "        breaks_pred = self.breaks_head(features)\n",
    "        return pattern_logits, sessions_pred, breaks_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd460ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000 - Loss: 1388.1778\n",
      "Epoch 50/4000 - Loss: 106.6095\n",
      "Epoch 100/4000 - Loss: 113.0415\n",
      "Epoch 150/4000 - Loss: 109.9143\n",
      "Epoch 200/4000 - Loss: 109.2724\n",
      "Epoch 250/4000 - Loss: 113.2789\n",
      "Epoch 300/4000 - Loss: 98.7195\n",
      "Epoch 350/4000 - Loss: 105.6547\n",
      "Epoch 400/4000 - Loss: 99.4540\n",
      "Epoch 450/4000 - Loss: 116.2709\n",
      "Epoch 500/4000 - Loss: 99.1657\n",
      "Epoch 550/4000 - Loss: 95.5776\n",
      "Epoch 600/4000 - Loss: 104.2946\n",
      "Epoch 650/4000 - Loss: 99.3476\n",
      "Epoch 700/4000 - Loss: 98.2269\n",
      "Epoch 750/4000 - Loss: 88.1567\n",
      "Epoch 800/4000 - Loss: 79.1940\n",
      "Epoch 850/4000 - Loss: 84.1394\n",
      "Epoch 900/4000 - Loss: 66.3664\n",
      "Epoch 950/4000 - Loss: 68.1198\n",
      "Epoch 1000/4000 - Loss: 56.1194\n",
      "Epoch 1050/4000 - Loss: 68.1148\n",
      "Epoch 1100/4000 - Loss: 62.2308\n",
      "Epoch 1150/4000 - Loss: 52.1847\n",
      "Epoch 1200/4000 - Loss: 61.7455\n",
      "Epoch 1250/4000 - Loss: 50.7458\n",
      "Epoch 1300/4000 - Loss: 53.6873\n",
      "Epoch 1350/4000 - Loss: 56.5480\n",
      "Epoch 1400/4000 - Loss: 47.5772\n",
      "Epoch 1450/4000 - Loss: 64.0207\n",
      "Epoch 1500/4000 - Loss: 64.3245\n",
      "Epoch 1550/4000 - Loss: 59.9751\n",
      "Epoch 1600/4000 - Loss: 48.5298\n",
      "Epoch 1650/4000 - Loss: 41.5369\n",
      "Epoch 1700/4000 - Loss: 44.0954\n",
      "Epoch 1750/4000 - Loss: 68.2553\n",
      "Epoch 1800/4000 - Loss: 48.6557\n",
      "Epoch 1850/4000 - Loss: 41.1763\n",
      "Epoch 1900/4000 - Loss: 38.2944\n",
      "Epoch 1950/4000 - Loss: 42.8158\n",
      "Epoch 2000/4000 - Loss: 40.4274\n",
      "Epoch 2050/4000 - Loss: 46.7282\n",
      "Epoch 2100/4000 - Loss: 46.4219\n",
      "Epoch 2150/4000 - Loss: 41.6287\n",
      "Epoch 2200/4000 - Loss: 36.7776\n",
      "Epoch 2250/4000 - Loss: 39.5422\n",
      "Epoch 2300/4000 - Loss: 39.9897\n",
      "Epoch 2350/4000 - Loss: 41.8617\n",
      "Epoch 2400/4000 - Loss: 42.3090\n",
      "Epoch 2450/4000 - Loss: 43.1347\n",
      "Epoch 2500/4000 - Loss: 35.2948\n",
      "Epoch 2550/4000 - Loss: 36.7654\n",
      "Epoch 2600/4000 - Loss: 49.9096\n",
      "Epoch 2650/4000 - Loss: 36.3698\n",
      "Epoch 2700/4000 - Loss: 36.2561\n",
      "Epoch 2750/4000 - Loss: 39.7702\n",
      "Epoch 2800/4000 - Loss: 40.2887\n",
      "Epoch 2850/4000 - Loss: 39.3664\n",
      "Epoch 2900/4000 - Loss: 43.9403\n",
      "Epoch 2950/4000 - Loss: 35.4463\n",
      "Epoch 3000/4000 - Loss: 39.3524\n",
      "Epoch 3050/4000 - Loss: 38.1056\n",
      "Epoch 3100/4000 - Loss: 38.1232\n",
      "Epoch 3150/4000 - Loss: 35.0158\n",
      "Epoch 3200/4000 - Loss: 38.1218\n",
      "Epoch 3250/4000 - Loss: 39.0611\n",
      "Epoch 3300/4000 - Loss: 34.0669\n",
      "Epoch 3350/4000 - Loss: 25.5050\n",
      "Epoch 3400/4000 - Loss: 38.6339\n",
      "Epoch 3450/4000 - Loss: 30.2801\n",
      "Epoch 3500/4000 - Loss: 36.3996\n",
      "Epoch 3550/4000 - Loss: 35.4675\n",
      "Epoch 3600/4000 - Loss: 32.2414\n",
      "Epoch 3650/4000 - Loss: 44.6240\n",
      "Epoch 3700/4000 - Loss: 26.4141\n",
      "Epoch 3750/4000 - Loss: 31.4884\n",
      "Epoch 3800/4000 - Loss: 24.0408\n",
      "Epoch 3850/4000 - Loss: 20.5177\n",
      "Epoch 3900/4000 - Loss: 20.7959\n",
      "Epoch 3950/4000 - Loss: 23.9952\n",
      "Epoch 4000/4000 - Loss: 29.4364\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PomodoroNet(num_patterns=len(PATTERN_LIST), max_sessions=MAX_SESSIONS).to(device)\n",
    "criterion_class = nn.CrossEntropyLoss()\n",
    "criterion_reg = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 4000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y_pat, y_sess, y_break in train_loader:\n",
    "        x, y_pat, y_sess, y_break = x.to(device), y_pat.to(device), y_sess.to(device), y_break.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pat_logits, sess_pred, break_pred = model(x)\n",
    "        loss_pat = criterion_class(pat_logits, y_pat)\n",
    "        loss_sess = criterion_reg(sess_pred, y_sess)\n",
    "        loss_break = criterion_reg(break_pred, y_break)\n",
    "        loss = loss_pat + loss_sess + loss_break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if (epoch+1) % 50 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2801cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'duration_minutes': 115, 'pattern': 'WSWSWL', 'work_sessions': [30, 30, 28], 'short_break': 5, 'long_break': 12}\n"
     ]
    }
   ],
   "source": [
    "def predict(duration_minutes: float) -> dict:\n",
    "    model.eval()\n",
    "    x = torch.tensor([[duration_minutes]], dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        pat_logits, sess_pred, break_pred = model(x)\n",
    "        pattern_idx = torch.argmax(pat_logits, dim=1).item()\n",
    "        pattern = IDX_TO_PATTERN[pattern_idx]\n",
    "\n",
    "        sessions = sess_pred[0].cpu().round().clamp(min=0).int().tolist()\n",
    "        needed = pattern.count('W')\n",
    "        sessions = sessions[:needed]\n",
    "        \n",
    "        breaks = break_pred[0].cpu().round().clamp(min=0).int().tolist()\n",
    "        short_break = breaks[0]\n",
    "        long_break = breaks[1] if 'L' in pattern else None\n",
    "\n",
    "        # Enforce: long_break > short_break if long_break exists\n",
    "        if long_break is not None:\n",
    "            if long_break <= short_break:\n",
    "                # Option 1: Make long_break at least short_break + 5\n",
    "                long_break = short_break + 5\n",
    "\n",
    "    return {\n",
    "        \"duration_minutes\": duration_minutes,\n",
    "        \"pattern\": pattern,\n",
    "        \"work_sessions\": sessions,\n",
    "        \"short_break\": short_break,\n",
    "        \"long_break\": long_break\n",
    "    }\n",
    "# Example usage:\n",
    "print(predict(115))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f0f51da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern accuracy: 91.04%\n",
      "Session MAE: 3.46\n",
      "Break MAE: 1.17\n"
     ]
    }
   ],
   "source": [
    "# Evaluate pattern prediction accuracy and MAE for regression outputs\n",
    "def evaluate(model, dataset):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    session_mae = 0\n",
    "    break_mae = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y_pat, y_sess, y_break in DataLoader(dataset, batch_size=64):\n",
    "            x = x.to(device)\n",
    "            pat_logits, sess_pred, break_pred = model(x)\n",
    "            pred_pat = torch.argmax(pat_logits, dim=1)\n",
    "            correct += (pred_pat.cpu() == y_pat).sum().item()\n",
    "            total += y_pat.size(0)\n",
    "            session_mae += (sess_pred.cpu() - y_sess).abs().sum().item()\n",
    "            break_mae += (break_pred.cpu() - y_break).abs().sum().item()\n",
    "    n = len(dataset)\n",
    "    print(f\"Pattern accuracy: {correct/total:.2%}\")\n",
    "    print(f\"Session MAE: {session_mae/(n*MAX_SESSIONS):.2f}\")\n",
    "    print(f\"Break MAE: {break_mae/(n*2):.2f}\")\n",
    "\n",
    "evaluate(model, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b18e2342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coded Output:\n",
      "115:00:WSWSWL:35:5:30:5:30:10:loss=00:00\n",
      "\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_code_str = optimized_pomodoro_playlist(\"115:00\", code_format=True)\n",
    "print(\"Coded Output:\")\n",
    "print(result_code_str)\n",
    "print(\"\\n------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3188ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"pomodoro_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b0ad1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration_minutes': 115,\n",
       " 'pattern': 'WSWSWL',\n",
       " 'work_sessions': [30, 30, 28],\n",
       " 'short_break': 5,\n",
       " 'long_break': 12}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PomodoroNet(num_patterns=len(PATTERN_LIST), max_sessions=MAX_SESSIONS)\n",
    "model.load_state_dict(torch.load(\"pomodoro_model.pth\"))\n",
    "model.to(device)  # Move to CUDA/CPU as appropriate\n",
    "model.eval()      # Set to evaluation mode (important for inference)\n",
    "\n",
    "predict(115)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
